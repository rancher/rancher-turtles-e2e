# This workflow is a reusable one called by other workflows
name: (template) Rancher Turtles E2E tests

on:
  workflow_call:
    # Variables to set when calling this reusable workflow
    secrets:
      gcp_credentials:
        description: Credentials to use to connect
        required: true
      pat_token:
        # A token is needed to be able to add runner on the repo, maybe this can be changed later
        # This token is linked to a personal account
        # So in case of token issue you have to check (no specific order and for example):
        # - the expiration date
        # - if the account associated still exists
        # - if the person still has access to the repo
        description: PAT token used to add runner
        required: true
      aws_access_key:
        description: AWS_ACCESS_KEY_ID required to create AWS Cloud credentials.
        required: true
      aws_secret_key:
        description: AWS_SECRET_ACCESS_KEY required to create AWS Cloud credentials.
        required: true
      qase_api_token:
        description: Qase API token to use for Qase reporting
        required: true
      rancher_password:
        description: Rancher login password
        required: true
    inputs:
      cert-manager_version:
        description: Version of cert-manager to use
        type: string
      cluster_name:
        description: Name of the provisioned cluster
        required: true
        type: string
      cluster_number:
        description: Number of clusters to deploy in multi-cluster test
        type: string
      destroy_runner:
        description: Destroy the auto-generated self-hosted runner
        default: true
        type: boolean
      capi_ui_version:
        description: Version of the capi ui which will be installed (dev/stable)
        default: dev
        type: string
      k8s_version_to_provision:
        description: Name and version of installed K8s distribution
        required: true
        type: string
      rancher_log_collector:
        description: URL of the Rancher log collector script
        default: https://raw.githubusercontent.com/rancherlabs/support-tools/master/collection/rancher/v2.x/logs-collector/rancher2_logs_collector.sh
        type: string
      rancher_version:
        description: Rancher Manager channel/version/head_version to use for installation
        default: stable/latest/none
        type: string
      rancher_upgrade:
        description: Rancher Manager channel/version to upgrade to
        type: string
      runner_template:
        description: Runner template to use
        default: capi-e2e-ci-runner-spot-n2-highmem-16-template-v2
        type: string
      test_description:
        description: Short description of the test
        type: string
      ui_account:
        description: Account used to test RBAC role in UI
        required: false
        type: string
      upstream_cluster_version:
        description: Cluster upstream version where to install Rancher (K3s or RKE2)
        default: v1.28.11+k3s1
        type: string
      zone:
        description: GCP zone to host the runner
        default: asia-south2-a
        type: string

env:
  QASE_API_TOKEN: ${{ secrets.QASE_API_TOKEN }}
  QASE_PROJECT_CODE: RT
  QASE_REPORT: 1
  QASE_RUN_COMPLETE: 1
  QASE_HELPER: ${{ github.workspace }}/tests/e2e/helpers/qase/helper_qase.go

jobs:
  create-runner:
    runs-on: ubuntu-latest
    outputs:
      uuid: ${{ steps.generator.outputs.uuid }}
      runner: ${{ steps.generator.outputs.runner }}
      public_dns: ${{ steps.dns.outputs.public_dns }}
    steps:
      # actions/checkout MUST come before auth
      - name: Checkout
        uses: actions/checkout@v4
      - name: Generate UUID and Runner hostname
        id: generator
        run: |
          # NOTE: keep the runner name to less than 63 characters!
          UUID=$(uuidgen)
          GH_REPO_FULL=${{ github.repository }}
          GH_REPO=${GH_REPO_FULL#*/}
          echo "uuid=${UUID//-}" >> ${GITHUB_OUTPUT}
          echo "runner=${GH_REPO//\//-}-ci-${UUID//-}" >> ${GITHUB_OUTPUT}
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.gcp_credentials }}
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
      - name: Create runner
        run: |
          gcloud compute instances create ${{ steps.generator.outputs.runner }} \
            --source-instance-template ${{ inputs.runner_template }} \
            --zone ${{ inputs.zone }}
      - name: Create GCP secrets
        run: |
          echo -n ${{ secrets.pat_token }} \
            | gcloud secrets create PAT_TOKEN_${{ steps.generator.outputs.uuid }} --data-file=-
          echo -n ${{ github.repository }} \
            | gcloud secrets create GH_REPO_${{ steps.generator.outputs.uuid }} --data-file=-
      - name: Get public dns name in GCP
        id: dns
        run: |
          # Do a timed out loop here, as gcloud can sometimes fail
          typeset -i i=0
          while true; do
            # Get public IP
            PUBLIC_IP=$(gcloud compute instances list 2> /dev/null \
                        | awk '/${{ steps.generator.outputs.runner }}/ {print $6}')
            # Exit if we reach the timeout or if IP is set
            if (( ++i > 10 )) || [[ -n "${PUBLIC_IP}" ]]; then
              break
            fi
            # Wait a little before retrying
            sleep 2
          done
          # Get the public DNS
          PUBLIC_DNS=$(host -l ${PUBLIC_IP} 2> /dev/null \
                       | awk '{sub(/\.$/, ""); print $5}')
          echo "public_dns=${PUBLIC_DNS}" >> ${GITHUB_OUTPUT}
          # Raise an error if either IP and/or DNS are empty
          if [[ -z "${PUBLIC_IP}" || -z "${PUBLIC_DNS}" ]]; then
            echo "PUBLIC_IP and/or PUBLIC_DNS are empty!" >&2
            false
          fi

  pre-qase:
    runs-on: ubuntu-latest
    outputs:
      qase_run_description: ${{ steps.qase.outputs.qase_run_description }}
      qase_run_id: ${{ steps.qase.outputs.qase_run_id }}
      qase_run_name: ${{ steps.qase.outputs.qase_run_name }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Install Go
        uses: actions/setup-go@v5
        with:
          go-version-file: tests/go.mod
      - name: Create/Export Qase Run
        id: qase
        run: |
          # Define and export URL of GH test run in Qase run description
          GH_RUN_URL="${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          export QASE_RUN_DESCRIPTION="${GH_RUN_URL}"
          export QASE_RUN_NAME="${GITHUB_WORKFLOW}"
        
          # Create a Qase run, get its ID
          ID=$(cd tests && go run ${{ env.QASE_HELPER }} -create)
          # Export outputs for future use
          echo "qase_run_id=${ID}" >> ${GITHUB_OUTPUT}
    
          # Just an info for debugging purposes
          echo -e "Exported values:\nQASE_RUN_ID=${ID}\nQASE_RUN_DESCRIPTION=${QASE_RUN_DESCRIPTION}\nQASE_RUN_NAME=${QASE_RUN_NAME}"
        
  e2e:
    needs: [create-runner, pre-qase]
    runs-on: ${{ needs.create-runner.outputs.uuid }}
    env:
      ARCH: amd64
      CERT_MANAGER_VERSION: ${{ inputs.cert-manager_version }}
      CLUSTER_NAME: ${{ inputs.cluster_name }}
      CLUSTER_NS: fleet-default
      # K3S / RKE2 flags to use for installation
      INSTALL_K3S_SKIP_ENABLE: true
      INSTALL_K3S_VERSION: ${{ inputs.upstream_cluster_version }}
      INSTALL_RKE2_VERSION: ${{ inputs.upstream_cluster_version }}
      K3S_KUBECONFIG_MODE: 0644
      # Distribution to use to host Rancher Manager (K3s or RKE2)
      K8S_UPSTREAM_VERSION: ${{ inputs.upstream_cluster_version }}
      # For K8s cluster to provision with Rancher Manager
      K8S_VERSION_TO_PROVISION: ${{ inputs.k8s_version_to_provision }}
      # For Rancher Manager
      RANCHER_VERSION: ${{ inputs.rancher_version }}
      TIMEOUT_SCALE: 3
      TAG: 0.0.1
      TURTLES_REPO: rancher-sandbox/rancher-turtles
      MANIFEST_IMG: localhost:5000/$TURTLES_REPO-$ARCH
    steps:
      - name: Add /usr/local/bin into PATH
        run: |
          echo "/usr/local/bin/" >> ${GITHUB_PATH}
          echo 'Defaults secure_path="/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin"' | sudo tee /etc/sudoers.d/0-custom_secure_path
      - name: Install helm
        run: curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
      # Build rancher-turtles nightly chart
      - name: Check out rancher-turtles repo
        uses: actions/checkout@v4
        with:
          repository: ${{ env.TURTLES_REPO }}
      - name: Install Go
        uses: actions/setup-go@v5
        with:
          go-version-file: go.mod

      # This step builds latest turtles chart and pushes latest turtles docker image to local docker registry
      - name: Make chart
        run: |
          TAG=v${{ env.TAG }} MANIFEST_IMG=${{ env.MANIFEST_IMG }} make docker-build
          RELEASE_TAG=v${{ env.TAG }} CONTROLLER_IMG=${{ env.MANIFEST_IMG }} CONTROLLER_IMAGE_VERSION=v${{ env.TAG }} make build-chart
          docker run -d -p 5000:5000 --name registry registry:2
          docker push ${{ env.MANIFEST_IMG }}:v${{ env.TAG }}

      - name: Copy chart file
        run: sudo cp ${{ github.workspace }}/out/package/rancher-turtles-${{ env.TAG }}.tgz ${{ runner.temp }}

      - name: Checkout
        uses: actions/checkout@v4
      - name: Install Go
        uses: actions/setup-go@v5
        with:
          go-version-file: tests/go.mod
      - name: Copy chart file for chartmuseum
        run: sudo cp ${{ runner.temp }}/rancher-turtles-${{ env.TAG }}.tgz ${{ github.workspace }}/tests/assets
      - name: Install preriquisite components
        env:
          PUBLIC_DNS: ${{ needs.create-runner.outputs.public_dns }}
          PUBLIC_DOMAIN: bc.googleusercontent.com
        run: cd tests && make e2e-install-rancher
      - name: Extract component versions/informations
        id: component
        run: |
          # Extract CertManager version
          CERT_MANAGER_VERSION=$(kubectl get pod \
                                   --namespace cert-manager \
                                   -l app=cert-manager \
                                   -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)
          # Extract Rancher Manager version
          RM_VERSION=$(kubectl get pod \
                         --namespace cattle-system \
                         -l app=rancher \
                         -o jsonpath={.items[*].status.containerStatuses[*].image} 2> /dev/null || true)
          # Export values
          echo "cert_manager_version=${CERT_MANAGER_VERSION}" >> ${GITHUB_OUTPUT}
          echo "rm_version=${RM_VERSION}" >> ${GITHUB_OUTPUT}
      - name: Install Chartmuseum
        run: cd tests && make e2e-install-chartmuseum
      - name: Cypress tests - Basics
        # Basics means tests without an extra elemental node needed
        env:
          BROWSER: chrome
          CHARTMUSEUM_REPO: http://${{ needs.create-runner.outputs.public_dns }}
          CYPRESS_DOCKER: 'cypress/included:13.6.4'
          CAPI_UI_VERSION: ${{ inputs.capi_ui_version }}
          K8S_UPSTREAM_VERSION: ${{ inputs.upstream_cluster_version }}
          RANCHER_VERSION: ${{ steps.component.outputs.rm_version }}
          RANCHER_PASSWORD: ${{ secrets.rancher_password }}
          RANCHER_URL: https://${{ needs.create-runner.outputs.public_dns }}/dashboard
          RANCHER_USER: admin
          AWS_ACCESS_KEY_ID: ${{ secrets.aws_access_key }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.aws_secret_key }}
          GCP_CREDENTIALS: ${{ secrets.gcp_credentials }}
          QASE_RUN_ID: ${{ needs.pre-qase.outputs.qase_run_id }}
          SPEC: |
            /workdir/e2e/unit_tests/first_connection.spec.ts
            /workdir/e2e/unit_tests/user.spec.ts
            /workdir/e2e/unit_tests/turtles_operator.spec.ts
            /workdir/e2e/unit_tests/turtles_plugin.spec.ts
            /workdir/e2e/unit_tests/menu.spec.ts
            /workdir/e2e/unit_tests/providers_setup.spec.ts
            /workdir/e2e/unit_tests/capd_clusterclass.spec.ts
            /workdir/e2e/unit_tests/capd_cluster.spec.ts
            /workdir/e2e/unit_tests/capa_cluster.spec.ts
          UI_ACCOUNT: ${{ inputs.ui_account }}
          UPGRADE_OS_CHANNEL: ${{ inputs.upgrade_os_channel }}
        run: cd tests && make start-cypress-tests
      - name: Upload Cypress screenshots (Basics)
        if: failure() 
        uses: actions/upload-artifact@v4
        with:
          name: cypress-screenshots-basics-${{ inputs.cluster_name }}
          path: tests/cypress/latest/screenshots
          retention-days: 7
          if-no-files-found: ignore
      - name: Upload Cypress videos (Basics)
        # Test run video is always captured, so this action uses "always()" condition
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cypress-videos-basics-${{ inputs.cluster_name }}
          path: tests/cypress/latest/videos
          retention-days: 7
      - name: Add summary
        if: ${{ always() }}
        run: |
          # Add summary
          echo "## General informations" >> ${GITHUB_STEP_SUMMARY}
          echo -e "***${{ inputs.test_description }}***\n" >> ${GITHUB_STEP_SUMMARY}
          echo "Type of cluster deployed: ${CLUSTER_TYPE:-normal}" >> ${GITHUB_STEP_SUMMARY}
          echo "### Rancher Manager" >> ${GITHUB_STEP_SUMMARY}
          echo "Rancher Manager Image: ${{ steps.component.outputs.rm_version }}" >> ${GITHUB_STEP_SUMMARY}
          echo "Rancher Manager Version: ${{ inputs.rancher_version }}" >> ${GITHUB_STEP_SUMMARY}
          echo "CertManager Image: ${{ steps.component.outputs.cert_manager_version }}" >> ${GITHUB_STEP_SUMMARY}
          echo "CAPI UI Extension Version: ${{ inputs.capi_ui_version }}" >> ${GITHUB_STEP_SUMMARY}
          if ${{ inputs.ui_account != '' }}; then
            echo "Elemental UI User: ${{ inputs.ui_account }}" >> ${GITHUB_STEP_SUMMARY}
          fi
          echo "### Kubernetes" >> ${GITHUB_STEP_SUMMARY}
          echo "K3s on Rancher Manager: ${{ env.INSTALL_K3S_VERSION }}" >> ${GITHUB_STEP_SUMMARY}
          echo "K8s version deployed on the cluster(s): ${{ inputs.k8s_version_to_provision }}" >> ${GITHUB_STEP_SUMMARY}
  delete-runner:
    if: ${{ always() }}
    needs: [create-runner, e2e]
    runs-on: ubuntu-latest
    steps:
      # actions/checkout MUST come before auth
      - name: Checkout
        uses: actions/checkout@v4
      - name: Authenticate to GCP
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.gcp_credentials }}
      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v2
      - name: Delete GCP secrets
        run: |
          gcloud --quiet secrets delete PAT_TOKEN_${{ needs.create-runner.outputs.uuid }} || true
          gcloud --quiet secrets delete GH_REPO_${{ needs.create-runner.outputs.uuid }} || true
      - name: Delete runner
        if: ${{ always() && needs.create-runner.result == 'success' && inputs.destroy_runner == true }}
        run: |
          gcloud --quiet compute instances delete ${{ needs.create-runner.outputs.runner }} \
            --delete-disks all \
            --zone ${{ inputs.zone }}

  post-qase:
    if: ${{ always() && needs.pre-qase.outputs.qase_run_id != '' }}
    needs: [e2e, pre-qase]
    runs-on: ubuntu-latest
    env:
      QASE_RUN_ID: ${{ needs.pre-qase.outputs.qase_run_id }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4          
      - name: Setup Go
        uses: actions/setup-go@v5
        with:
          go-version-file: tests/go.mod
      - name: Finalize Qase Run and publish Results
        if: ${{ always() && !contains(needs.e2e.result, 'cancelled') }}
        run: |
          REPORT=$(cd tests && go run ${{ env.QASE_HELPER }} -publish)
          echo "${REPORT}"
      - name: Delete Qase Run if job has been cancelled
        if: ${{ always() && contains(needs.e2e.result, 'cancelled') }}
        run: cd tests && go run ${{ env.QASE_HELPER }} -delete
